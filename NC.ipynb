{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pF3KcCPgs2hq"
      },
      "id": "pF3KcCPgs2hq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e41cf33",
      "metadata": {
        "id": "3e41cf33"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch import device\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/Cours/ensta cours/CSC_5IA23_TA_Project-main/\")\n",
        "from ResNet import ResNet18\n",
        "torch.manual_seed(47)\n",
        "np.random.seed(47)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4468aae2",
      "metadata": {
        "id": "4468aae2"
      },
      "outputs": [],
      "source": [
        "tr = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "data = torchvision.datasets.CIFAR100(\n",
        "    root=\"./data\", train=False, download=True, transform=tr\n",
        ")\n",
        "batch_size = 32\n",
        "train_size = int(0.9* len(data))\n",
        "val_size = int(0.1*len(data))\n",
        "train_data, val_data = torch.utils.data.random_split(data, [train_size, val_size])\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dba2d22c",
      "metadata": {
        "id": "dba2d22c"
      },
      "source": [
        "# Neural Collapse\n",
        "\n",
        "### separating the data per class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef63101",
      "metadata": {
        "id": "7ef63101"
      },
      "outputs": [],
      "source": [
        "def load_model(path):\n",
        "    d = torch.load(path)\n",
        "    d[\"cl.weight\"] = d[\"model.13.weight\"]\n",
        "    d[\"cl.bias\"] = d[\"model.13.bias\"]\n",
        "    d.pop(\"model.13.weight\")\n",
        "    d.pop(\"model.13.bias\")\n",
        "    resnet = ResNet18(64,2,100).to(device)\n",
        "    resnet.load_state_dict(d)\n",
        "    return resnet\n",
        "# resnet = load_model(\"/content/drive/MyDrive/Cours/ensta cours/model/resnet_360_epoch.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_features(path,dataloader):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  resnet = load_model(path)\n",
        "  resnet.eval()\n",
        "  features = torch.tensor([],requires_grad=False,device=device)\n",
        "  l = torch.tensor([],requires_grad=False,device=device)\n",
        "  pred = torch.tensor([],requires_grad=False,device=device)\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in tqdm(dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        out = resnet.model(inputs)\n",
        "        features = torch.cat((features,out))\n",
        "        l = torch.cat((l,labels))\n",
        "        pred = torch.cat((pred,torch.argmax(resnet.cl(out),dim=1)))\n",
        "  W = resnet.cl.weight.data\n",
        "  del resnet\n",
        "  return features, l, W, pred\n",
        "\n",
        "\n",
        "def get_mu_G(features):\n",
        "  return torch.mean(features,dim=0).to(device)\n",
        "\n",
        "def get_sigma_T(features,mu_G):\n",
        "  t = features - mu_G\n",
        "  t = t.T @ t / (features.shape[0])\n",
        "  return t\n",
        "  # return (features.T @ features) / (features.shape[0])\n",
        "\n",
        "def get_sigma_B(mu_C_list,mu_G):\n",
        "  sigma_B = torch.zeros((mu_G.shape[0],mu_G.shape[0]),device=device)\n",
        "  for mu_C in mu_C_list:\n",
        "    diff = mu_C - mu_G\n",
        "    sigma_B += diff.unsqueeze(1) @ diff.unsqueeze(0) # Corrected outer product\n",
        "  sigma_B /= len(mu_C_list)\n",
        "  return sigma_B\n",
        "\n",
        "def get_mu_C_list(features,labels):\n",
        "  mu_C_list = []\n",
        "  for i in range(100):\n",
        "    mu_C_list.append(torch.mean(features[labels == i],dim=0).to(device))\n",
        "  return mu_C_list"
      ],
      "metadata": {
        "id": "L59Ilrzrud_-"
      },
      "id": "L59Ilrzrud_-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ea1889e2",
      "metadata": {
        "id": "ea1889e2"
      },
      "source": [
        "## NC 1\n",
        "\n",
        "variability collapse : In class variations converges towards 0.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f78d2f44",
      "metadata": {
        "id": "f78d2f44"
      },
      "outputs": [],
      "source": [
        "def nc1(sigma_W):\n",
        "  return torch.linalg.norm(sigma_W)\n",
        "\n",
        "def train_class_means_equinorm(mu_C_list,mu_G):\n",
        "  centered_norms = []\n",
        "  for key in range(len(mu_C_list)):\n",
        "    centered_norms.append(torch.linalg.norm(mu_C_list[key] - mu_G))\n",
        "  #Fig 2\n",
        "  centered_norms = torch.tensor(centered_norms,device=device)\n",
        "  return torch.std(centered_norms) / torch.mean(centered_norms)\n",
        "\n",
        "def train_class_weights_equinorm(weights):\n",
        "  norm = torch.sum(weights**2,dim=1)\n",
        "  # print(norm.shape)\n",
        "  # print(norm)\n",
        "  #Fig 2\n",
        "  m = torch.mean(norm)\n",
        "  s = torch.std(norm)\n",
        "  # print(m)\n",
        "  # print(s)\n",
        "  return  s/m\n",
        "\n",
        "def scale_invariante_nc1(Sigma_W, Sigma_B):\n",
        "    \"\"\"\n",
        "    Computes the NC1 metric: 1/C * Trace(Sigma_W * pinv(Sigma_B))\n",
        "    \"\"\"\n",
        "    C = Sigma_B.shape[0] # Number of classes\n",
        "    Sigma_B_pinv = torch.linalg.pinv(Sigma_B, rcond=1e-6)\n",
        "    # NC1 = 1/C * Trace(Sigma_W @ Sigma_B_pinv)\n",
        "    nc1_value = torch.trace(Sigma_W @ Sigma_B_pinv) / C\n",
        "\n",
        "    #Fig 6\n",
        "    return nc1_value.item()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e4bab00",
      "metadata": {
        "id": "6e4bab00"
      },
      "source": [
        "## NC 2\n",
        "\n",
        "As training progresses, the standard deviations of the cosines approach zero\n",
        "indicating equiangularity\n",
        "\n",
        "\\begin{aligned}\n",
        "    \\left| \\|\\mu_c - \\mu_G\\|_2 - \\|\\mu_{c'} - \\mu_G\\|_2 \\right| &\\to 0 \\quad \\forall c, c' \\newline\n",
        "    \\langle \\tilde{\\mu}_c, \\tilde{\\mu}_{c'} \\rangle &\\to \\frac{C}{C-1} \\delta_{c,c'} - \\frac{1}{C-1} \\quad \\forall c, c'\n",
        "\\end{aligned}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nc2(mu_C_list,mu_G):\n",
        "  class_cos_sim = []\n",
        "  for key in range(len(mu_C_list)):\n",
        "    for key2 in range(len(mu_C_list)):\n",
        "      if key < key2: #maybe we dont have to this\n",
        "        continue\n",
        "      norm=  (mu_C_list[key] -mu_G )@ (mu_C_list[key2] - mu_G)\n",
        "      norm = norm/(torch.linalg.norm(mu_C_list[key] - mu_G)*torch.linalg.norm(mu_C_list[key2] - mu_G)   )\n",
        "      class_cos_sim.append(norm)\n",
        "\n",
        "  class_cos_sim = torch.tensor(class_cos_sim,device=device)\n",
        "  vals_2 = torch.std(class_cos_sim)\n",
        "  vals_3 = class_cos_sim + 1/(class_cos_sim.shape[0] - 1)\n",
        "  vals_3 = torch.mean(vals_3)\n",
        "  #Fig 3, Fig 4\n",
        "  return vals_2,vals_3"
      ],
      "metadata": {
        "id": "yy3QCk61zYxP"
      },
      "id": "yy3QCk61zYxP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d8f76640",
      "metadata": {
        "id": "d8f76640"
      },
      "source": [
        "## NC 3\n",
        "\n",
        " Convergence to self-duality:\n",
        "\n",
        "$$ \\left\\| \\frac{W^T}{\\|W|_F} - \\frac{\\dot M}{\\|\\dot M|_F}\\right\\|_F \\to 0$$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nc3(mu_C_list,mu_G,W):\n",
        "  mu_C_list = torch.stack(mu_C_list) - mu_G\n",
        "  mu_C_list = mu_C_list / torch.linalg.norm(mu_C_list,dim=1,keepdim=True)\n",
        "\n",
        "  W = W / torch.linalg.norm(W,dim=0,keepdim=True)\n",
        "\n",
        "  #Fig 5\n",
        "  return torch.linalg.norm(mu_C_list.T - W.T)**2"
      ],
      "metadata": {
        "id": "NzRcgH5r5j5U"
      },
      "id": "NzRcgH5r5j5U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "84f0b7be",
      "metadata": {
        "id": "84f0b7be"
      },
      "source": [
        "## NC 4\n",
        "Simplification to NCC\n",
        "$$ arg\\max_{c'} \\left< w_{c'}, h \\right> + b_{c'} \\to \\arg\\min_{c'} \\|h - \\mu_{c'}\\|_2 $$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_nc4_disagreement(features, mpred, mu_C_list):\n",
        "    \"\"\"\n",
        "    Computes the disagreement between the model's logits and the NCC rule.\n",
        "\n",
        "    Args:\n",
        "        features (N, d): Penultimate layer features.\n",
        "        logits (N, C): Model output (before softmax).\n",
        "        class_means (C, d): The computed mu_c for each class.\n",
        "\n",
        "    Returns:\n",
        "        disagreement_rate (float): Percentage of samples where Model != NCC.\n",
        "    \"\"\"\n",
        "    # 2. Compute NCC predictions using vectorized L2 distance:\n",
        "    # ||h - mu||^2 = ||h||^2 + ||mu||^2 - 2<h, mu>\n",
        "    h_squared = torch.sum(features**2, dim=1, keepdim=True)      # (N, 1)\n",
        "    class_means = torch.stack(mu_C_list)\n",
        "    mu_squared = torch.sum(class_means**2, dim=1, keepdim=True).T # (1, C)\n",
        "    distances = h_squared + mu_squared - 2 * (features @ class_means.T)\n",
        "\n",
        "    ncc_preds = torch.argmin(distances, dim=1)\n",
        "    disagreement = (mpred != ncc_preds).float().mean()\n",
        "    # Fig 7\n",
        "    return disagreement.item()\n"
      ],
      "metadata": {
        "id": "jcaA6RZs9Vo1"
      },
      "id": "jcaA6RZs9Vo1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "eec19a17",
      "metadata": {
        "id": "eec19a17"
      },
      "source": [
        "## NC 5\n",
        "\n",
        "As training progresses, the clusters of OOD become increasingly orthgonal to the ETF subspace of the ID data."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zZXk2DNACHMO"
      },
      "id": "zZXk2DNACHMO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computing NC values"
      ],
      "metadata": {
        "id": "XiltBe3vCIDh"
      },
      "id": "XiltBe3vCIDh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e338fe5",
      "metadata": {
        "id": "8e338fe5"
      },
      "outputs": [],
      "source": [
        "fig2_1,fig2_2, fig3 , fig4 ,fig5, fig6, fig7 =[],[],[],[],[],[],[]\n",
        "nc1_fig = []\n",
        "for i in range(10,361,10):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  path = f\"/content/drive/MyDrive/Cours/ensta cours/model/resnet_{i}_epoch.pth\"\n",
        "  features,labels,W,pred = compute_features(path,train_dataloader)\n",
        "\n",
        "  mu_G = get_mu_G(features)\n",
        "  sigma_T = get_sigma_T(features,mu_G)\n",
        "  mu_C_list = get_mu_C_list(features,labels)\n",
        "  sigma_B = get_sigma_B(mu_C_list,mu_G)\n",
        "  # print(\"features :\",features.shape)\n",
        "  # print(\"labels :\",labels.shape)\n",
        "  # print(\"W :\",W.shape)\n",
        "  # print(\"pred :\",pred.shape)\n",
        "  # print(\"mu_G :\",mu_G.shape)\n",
        "  # print(\"mu_C_list :\",len(mu_C_list))\n",
        "  # print(\"mu_C_list[0] :\",mu_C_list[0].shape)\n",
        "  # print(\"sigma_T :\",sigma_T.shape)\n",
        "  # print(\"sigma_B :\",sigma_B.shape)\n",
        "\n",
        "  nc1_fig.append(nc1(sigma_T-sigma_B).item())\n",
        "  fig6.append(scale_invariante_nc1(sigma_T-sigma_B,sigma_B))\n",
        "  fig2_1.append(train_class_means_equinorm(mu_C_list,mu_G).item())\n",
        "  fig2_2.append(train_class_weights_equinorm(W).item())\n",
        "  x,y = nc2(mu_C_list,mu_G)\n",
        "  fig3.append(x.item())\n",
        "  fig4.append(y.item())\n",
        "  fig5.append(nc3(mu_C_list,mu_G,W).item())\n",
        "  fig7.append(compute_nc4_disagreement(features,pred, mu_C_list))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(nc1_fig)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YkEOvQ8KhFCH"
      },
      "id": "YkEOvQ8KhFCH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(fig2_1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3bdDt1yzI_xk"
      },
      "id": "3bdDt1yzI_xk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(fig2_2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XTC0DM_9MDSi"
      },
      "id": "XTC0DM_9MDSi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(fig3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KVgiwkAhMEhS"
      },
      "id": "KVgiwkAhMEhS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(fig4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7Bq2XK72MF3y"
      },
      "id": "7Bq2XK72MF3y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(fig5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z4NqoFHOMHL6"
      },
      "id": "Z4NqoFHOMHL6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(fig6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gtdJuVTvMIWW"
      },
      "id": "gtdJuVTvMIWW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(fig7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-t3N7IagMJZl"
      },
      "id": "-t3N7IagMJZl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "timeline = [i for i in range(10,361,10)]\n",
        "df = pd.DataFrame(\n",
        "    {\n",
        "        \"epochs\":timeline,\n",
        "        \"nc1_fig\":nc1_fig,\n",
        "        \"fig6_nc1_scale_invariant\":fig6,\n",
        "        \"fig2_1_train_class_means_equinorm\":fig2_1,\n",
        "        \"fig2_2_train_class_weights_equinorm\":fig2_2,\n",
        "        \"fig3_nc2_std_cos_sim\":fig3,\n",
        "        \"fig4_nc2_mean_cos_sim\":fig4,\n",
        "        \"fig5_nc3\":fig5,\n",
        "        \"fig7_nc4_disagreement\":fig7\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "O_Qqm2dR1cV5"
      },
      "id": "O_Qqm2dR1cV5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"nc_values.csv\")"
      ],
      "metadata": {
        "id": "UIzomH1b2Y-i"
      },
      "id": "UIzomH1b2Y-i",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}