{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF3KcCPgs2hq",
        "outputId": "b449596c-12f9-477c-8a38-8eece9fae4a5"
      },
      "id": "pF3KcCPgs2hq",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3e41cf33",
      "metadata": {
        "id": "3e41cf33"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch import device\n",
        "from tqdm.notebook import tqdm\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/Cours/ensta cours/CSC_5IA23_TA_Project-main/\")\n",
        "from ResNet import ResNet18\n",
        "torch.manual_seed(47)\n",
        "np.random.seed(47)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4468aae2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4468aae2",
        "outputId": "c1ae1920-cb01-4df2-accf-ca81f1ebeec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:01<00:00, 104MB/s]\n"
          ]
        }
      ],
      "source": [
        "tr = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "data = torchvision.datasets.CIFAR100(\n",
        "    root=\"./data\", train=False, download=True, transform=tr\n",
        ")\n",
        "batch_size = 32\n",
        "datal = torch.utils.data.DataLoader(data, batch_size=batch_size*2, shuffle=False, num_workers=2, )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dba2d22c",
      "metadata": {
        "id": "dba2d22c"
      },
      "source": [
        "# Neural Collapse\n",
        "\n",
        "### separating the data per class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7ef63101",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "7ef63101",
        "outputId": "e3f9c173-6e41-4f19-e0c0-670c6a44364e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2734283419.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mresnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Cours/ensta cours/model/resnet_360_epoch.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2734283419.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cl.weight\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model.13.weight\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cl.bias\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model.13.bias\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.13.weight\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m                         return _load(\n\u001b[0m\u001b[1;32m   1522\u001b[0m                             \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m                             \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2122\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2123\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_weights_only_unpickler.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    533\u001b[0m                         \u001b[0;34mf\"Only persistent_load of storage is allowed, but got {pid[0]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                     )\n\u001b[0;32m--> 535\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mBINGET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLONG_BINGET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mBINGET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<I\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   2084\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2086\u001b[0;31m             typed_storage = load_tensor(\n\u001b[0m\u001b[1;32m   2087\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2088\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   2050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_fake_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2052\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2053\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m             \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fake_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \"\"\"\n\u001b[1;32m    697\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mbackend_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_privateuse1_backend_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mdevice_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is_available\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdevice_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    606\u001b[0m             \u001b[0;34mf\"Attempting to deserialize object on a {backend_name.upper()} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;34mf\"device but torch.{backend_name}.is_available() is False. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ],
      "source": [
        "def load_model(path):\n",
        "    d = torch.load(path)\n",
        "    d[\"cl.weight\"] = d[\"model.13.weight\"]\n",
        "    d[\"cl.bias\"] = d[\"model.13.bias\"]\n",
        "    d.pop(\"model.13.weight\")\n",
        "    d.pop(\"model.13.bias\")\n",
        "    resnet = ResNet18(64,2,100).to(device)\n",
        "    resnet.load_state_dict(d)\n",
        "    return resnet\n",
        "resnet = load_model(\"/content/drive/MyDrive/Cours/ensta cours/model/resnet_360_epoch.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x= {\n",
        "    \"as\" : [6,5,6,1],\n",
        "    \"is\" : [6,5,68,4,6351,]\n",
        "}\n",
        "list(x.values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64S67wiguyAK",
        "outputId": "d65f2901-d4fb-4ba6-9ddc-e4d15e6c3e5c"
      },
      "id": "64S67wiguyAK",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 5, 6, 1], [6, 5, 68, 4, 6351]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_features(path,dataloader):\n",
        "  resnet = load_model(path)\n",
        "  resnet.eval()\n",
        "  features = torch.tensor([],requires_grad=False)\n",
        "  with torch.no_grad():\n",
        "    #start with an empty tensor\n",
        "    for inputs, labels in tqdm(dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        out = resnet.model(inputs)\n",
        "        features = torch.cat((features,out))\n",
        "  del resnet\n",
        "  return features\n",
        "\n",
        "\n",
        "def get_mu_G(features):\n",
        "  return torch.mean(features,dim=0)\n",
        "\n",
        "def get_sigma_T(features,mu_G):\n",
        "  return (features @ features.T) / (features.shape[0])\n",
        "\n",
        "def get_sigma_B(mu_C_list,mu_G)\n",
        "  sigma_B = torch.zeros((mu_G.shape[0],mu_G.shape[0]))\n",
        "  for mu_C in mu_C_list:\n",
        "    sigma_B += (mu_C - mu_G) @ (mu_C - mu_G).T\n",
        "  sigma_B /= len(mu_C_list)\n",
        "  return sigma_B\n",
        "\n",
        "def get_mu_C_list(features,labels):\n",
        "  mu_C_list = []\n",
        "  for i in range(100):\n",
        "    mu_C_list.append(torch.mean(features[labels == i],dim=0))\n",
        "  return mu_C_list\n",
        "\n"
      ],
      "metadata": {
        "id": "L59Ilrzrud_-"
      },
      "id": "L59Ilrzrud_-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ea1889e2",
      "metadata": {
        "id": "ea1889e2"
      },
      "source": [
        "## NC 1\n",
        "\n",
        "variability collapse : In class variations converges towards 0.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f78d2f44",
      "metadata": {
        "id": "f78d2f44"
      },
      "outputs": [],
      "source": [
        "def nc1(sigma_T,sigma_B):\n",
        "  return torch.linalg.norm(sigma_T - sigma_B)\n",
        "\n",
        "\n",
        "def train_class_means_equinorm(mu_C_list,mu_G):\n",
        "  centered_norms = []\n",
        "  for key in range(len(mu_C_list)):\n",
        "    centered_norms.append(torch.linalg.vector_norm(mu_C_list[key] - mu_G))\n",
        "  #Fig 2\n",
        "  return torch.std(centered_norms) / torch.mean(centered_norms)\n",
        "\n",
        "def train_class_weights_equinorm(weights):\n",
        "  norm = torch.linalg.norm(weights)\n",
        "  #Fig 2\n",
        "  return torch.std(norm) / torch.mean(norm)\n",
        "\n",
        "def scale_invariante_nc1(Sigma_W, Sigma_B):\n",
        "    \"\"\"\n",
        "    Computes the NC1 metric: 1/C * Trace(Sigma_W * pinv(Sigma_B))\n",
        "    \"\"\"\n",
        "    C = Sigma_B.shape[0] # Number of classes\n",
        "    Sigma_B_pinv = torch.linalg.pinv(Sigma_B, rcond=1e-6)\n",
        "    # NC1 = 1/C * Trace(Sigma_W @ Sigma_B_pinv)\n",
        "    nc1_value = torch.trace(Sigma_W @ Sigma_B_pinv) / C\n",
        "\n",
        "    #Fig 6\n",
        "    return nc1_value.item()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e4bab00",
      "metadata": {
        "id": "6e4bab00"
      },
      "source": [
        "## NC 2\n",
        "\n",
        "As training progresses, the standard deviations of the cosines approach zero\n",
        "indicating equiangularity\n",
        "\n",
        "\\begin{aligned}\n",
        "    \\left| \\|\\mu_c - \\mu_G\\|_2 - \\|\\mu_{c'} - \\mu_G\\|_2 \\right| &\\to 0 \\quad \\forall c, c' \\newline\n",
        "    \\langle \\tilde{\\mu}_c, \\tilde{\\mu}_{c'} \\rangle &\\to \\frac{C}{C-1} \\delta_{c,c'} - \\frac{1}{C-1} \\quad \\forall c, c'\n",
        "\\end{aligned}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nc2(mu_C_list,mu_G):\n",
        "  class_cos_sim = []\n",
        "  for key in range(len(mu_C_list)):\n",
        "    for key2 in range(len(mu_C_list)):\n",
        "      if key < key2: #maybe we dont have to this\n",
        "        continue\n",
        "      norm=  (mu_C_list[key] -mu_G )@ (mu_C_list[key2] - mu_G)\n",
        "      norm = norm/(torch.linalg.vector_norm(mu_C_list[key] - mu_G)*torch.linalg.vector_norm(mu_C_list[key2] - mu_G)   )\n",
        "      class_cos_sim.append(norm)\n",
        "\n",
        "  class_cos_sim = torch.tensor(class_cos_sim)\n",
        "  vals_2 = torch.std(class_cos_sim)\n",
        "  vals_3 = class_cos_sim + 1/(class_cos_sim.shape[0] - 1)\n",
        "  vals_3 = torch.mean(vals_3)\n",
        "  #Fig 3, Fig 4\n",
        "  return vals_2,vals_3"
      ],
      "metadata": {
        "id": "yy3QCk61zYxP"
      },
      "id": "yy3QCk61zYxP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d8f76640",
      "metadata": {
        "id": "d8f76640"
      },
      "source": [
        "## NC 3\n",
        "\n",
        " Convergence to self-duality:\n",
        "\n",
        "$$ \\left\\| \\frac{W^T}{\\|W|_F} - \\frac{\\dot M}{\\|\\dot M|_F}\\right\\|_F \\to 0$$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nc3(mu_C_list,mu_G,W):\n",
        "  mu_C_list = torch.stack(mu_C_list) - mu_G\n",
        "  mu_C_list = mu_C_list / torch.linalg.norm(mu_C_list,dim=1,keepdim=True)\n",
        "\n",
        "  W = W / torch.linalg.norm(W,dim=0,keepdim=True)\n",
        "\n",
        "  #Fig 5\n",
        "  return torch.linalg.norm(mu_C_list.T - W.T)**2"
      ],
      "metadata": {
        "id": "NzRcgH5r5j5U"
      },
      "id": "NzRcgH5r5j5U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "84f0b7be",
      "metadata": {
        "id": "84f0b7be"
      },
      "source": [
        "## NC 4\n",
        "Simplification to NCC\n",
        "$$ arg\\max_{c'} \\left< w_{c'}, h \\right> + b_{c'} \\to \\arg\\min_{c'} \\|h - \\mu_{c'}\\|_2 $$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_nc4_disagreement(features, logits, class_means):\n",
        "    \"\"\"\n",
        "    Computes the disagreement between the model's logits and the NCC rule.\n",
        "\n",
        "    Args:\n",
        "        features (N, d): Penultimate layer features.\n",
        "        logits (N, C): Model output (before softmax).\n",
        "        class_means (C, d): The computed mu_c for each class.\n",
        "\n",
        "    Returns:\n",
        "        disagreement_rate (float): Percentage of samples where Model != NCC.\n",
        "    \"\"\"\n",
        "    mpred = torch.argmax(logits, dim=1)\n",
        "\n",
        "    # 2. Compute NCC predictions using vectorized L2 distance:\n",
        "    # ||h - mu||^2 = ||h||^2 + ||mu||^2 - 2<h, mu>\n",
        "    h_squared = torch.sum(features**2, dim=1, keepdim=True)      # (N, 1)\n",
        "    mu_squared = torch.sum(class_means**2, dim=1, keepdim=True).T # (1, C)\n",
        "    distances = h_squared + mu_squared - 2 * (features @ class_means.T)\n",
        "\n",
        "    ncc_preds = torch.argmin(distances, dim=1)\n",
        "    disagreement = (mpred != ncc_preds).float().mean()\n",
        "    # Fig 7\n",
        "    return disagreement.item()\n"
      ],
      "metadata": {
        "id": "jcaA6RZs9Vo1"
      },
      "id": "jcaA6RZs9Vo1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "eec19a17",
      "metadata": {
        "id": "eec19a17"
      },
      "source": [
        "## NC 5\n",
        "\n",
        "As training progresses, the clusters of OOD become increasingly orthgonal to the ETF subspace of the ID data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e338fe5",
      "metadata": {
        "id": "8e338fe5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cb26b48",
      "metadata": {
        "id": "3cb26b48"
      },
      "outputs": [],
      "source": [
        "#load the model\n",
        "tab = []\n",
        "for epoch in range(360,361,10):# CHange this\n",
        "  path = f\"/content/drive/MyDrive/resnet_360_epoch.pth\"\n",
        "  # resnet = ResNet18(64,2,100).to(device)\n",
        "  # resnet.load_state_dict(torch.load(path))\n",
        "  resnet.eval()\n",
        "  features ={i:[] for i in range(100)}\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in tqdm(datal):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        out = resnet.model(inputs)\n",
        "        for i in range(len(labels)):\n",
        "            features[labels[i].item()].append(out[i])\n",
        "  for key in features.keys():\n",
        "    features[key] = torch.stack(features[key])\n",
        "  vars = {i:[] for i in range(100)}\n",
        "  tmp = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b05b886d",
      "metadata": {
        "id": "b05b886d"
      },
      "outputs": [],
      "source": [
        "mu_G = torch.mean(torch.cat(list(features.values())),dim=0)\n",
        "print(global_mean_vector.shape)\n",
        "# global_var_vector = torch.var(torch.cat(list(features.values())),dim=0)\n",
        "# print(global_var_vector.shape)\n",
        "\n",
        "#W the last layer weights\n",
        "weights = resnet.cl.weight.data\n",
        "print(weights.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ns-p_S8WuZBH"
      },
      "id": "ns-p_S8WuZBH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CSyL1BacuH8N"
      },
      "id": "CSyL1BacuH8N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a63a957",
      "metadata": {
        "id": "4a63a957"
      },
      "outputs": [],
      "source": [
        "vars = {i:[] for i in range(100)}\n",
        "class_means = {i:[] for i in range(100)} # globally centered class mean\n",
        "# tmp_T = []\n",
        "# tmp_B = []\n",
        "# tmp_W = []\n",
        "centered_norms = []\n",
        "weights\n",
        "for key in features.keys():\n",
        "  norm = features[key]  # - global_mean_vector\n",
        "  class_means[key] = torch.mean(norm,dim=0)\n",
        "  # vars[key] = torch.var(norm,dim=0)\n",
        "  centered_norms.append(torch.linalg.vector_norm(class_means[key] - global_mean_vector))\n",
        "\n",
        "centered_norms = torch.tensor(centered_norms)\n",
        "#Fig 2.\n",
        "vals_1 = torch.std(centered_norms) / torch.mean(centered_norms)\n",
        "\n",
        "class_cos_sim = []\n",
        "for key in class_means.keys():\n",
        "  for key2 in class_means.keys():\n",
        "    if key < key2:\n",
        "      continue\n",
        "    norm=  (class_means[key] -global_mean_vector )@ (class_means[key2] - global_mean_vector)\n",
        "    norm = norm/(torch.linalg.vector_norm(class_means[key] - global_mean_vector)*torch.linalg.vector_norm(class_means[key2] - global_mean_vector)   )\n",
        "\n",
        "    class_cos_sim.append(norm)\n",
        "#Fig 3\n",
        "class_cos_sim = torch.tensor(class_cos_sim)\n",
        "vals_2 = torch.std(class_cos_sim)\n",
        "#Fig 4\n",
        "vals_3 = class_cos_sim + 1/(class_cos_sim.shape[0] - 1)\n",
        "vals_3 = torch.mean(vals_3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56d3ca50",
      "metadata": {
        "id": "56d3ca50"
      },
      "outputs": [],
      "source": [
        "print(vals_1)\n",
        "print(vals_2)\n",
        "print(vals_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b87425ca",
      "metadata": {
        "id": "b87425ca"
      },
      "outputs": [],
      "source": [
        "#Fig 5\n",
        "\n",
        "\n",
        "\n",
        "#Fig 6.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Fig 7.\n",
        "\n",
        "\n",
        "# sigma_T =\n",
        "# sigma_B\n",
        "# sigma_W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "364d2687",
      "metadata": {
        "id": "364d2687"
      },
      "outputs": [],
      "source": [
        "print(vals_4)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}