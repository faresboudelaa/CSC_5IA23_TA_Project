{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pF3KcCPgs2hq",
      "metadata": {
        "id": "pF3KcCPgs2hq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e41cf33",
      "metadata": {
        "id": "3e41cf33"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch import device\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "import sys\n",
        "!cp \"/content/drive/MyDrive/Cours/ensta cours/CSC_5IA23_TA_Project-main/ResNet.py\" ./ResNet.py\n",
        "from ResNet import ResNet18\n",
        "torch.manual_seed(47)\n",
        "np.random.seed(47)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4468aae2",
      "metadata": {
        "id": "4468aae2"
      },
      "outputs": [],
      "source": [
        "tr = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "data = torchvision.datasets.CIFAR100(\n",
        "    root=\"./data\", train=True, download=True, transform=tr\n",
        ")\n",
        "batch_size = 32\n",
        "train_size = int(0.9* len(data))\n",
        "print(train_size )\n",
        "val_size = int(0.1*len(data))\n",
        "train_data, val_data = torch.utils.data.random_split(data, [train_size, val_size])\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dba2d22c",
      "metadata": {
        "id": "dba2d22c"
      },
      "source": [
        "# Neural Collapse\n",
        "\n",
        "### separating the data per class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef63101",
      "metadata": {
        "id": "7ef63101"
      },
      "outputs": [],
      "source": [
        "def load_model(path):\n",
        "    d = torch.load(path)\n",
        "    d[\"cl.weight\"] = d[\"model.13.weight\"]\n",
        "    d[\"cl.bias\"] = d[\"model.13.bias\"]\n",
        "    d.pop(\"model.13.weight\")\n",
        "    d.pop(\"model.13.bias\")\n",
        "    resnet = ResNet18(64,2,100).to(device)\n",
        "    resnet.load_state_dict(d)\n",
        "    return resnet\n",
        "# resnet = load_model(\"/content/drive/MyDrive/Cours/ensta cours/model/resnet_360_epoch.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8ab0fb9",
      "metadata": {
        "id": "d8ab0fb9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "L59Ilrzrud_-",
      "metadata": {
        "id": "L59Ilrzrud_-"
      },
      "outputs": [],
      "source": [
        "def compute_features(resnet,dataloader):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  resnet.eval()\n",
        "  feats, labels_list, preds = [], [], []\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in tqdm(dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        out = resnet.model(inputs)\n",
        "        feats.append(out)\n",
        "        labels_list.append(labels)\n",
        "        preds.append(torch.argmax(resnet.cl(out),dim=1))\n",
        "  W = resnet.cl.weight.data\n",
        "  return torch.cat(feats,dim=0), torch.cat(labels_list,dim=0), W, torch.cat(preds,dim=0)\n",
        "\n",
        "\n",
        "def get_mu_G(features):\n",
        "  return torch.mean(features,dim=0).to(device)\n",
        "\n",
        "def get_sigma_T(features,mu_G):\n",
        "  t = features - mu_G\n",
        "  t = t.T @ t / (features.shape[0])\n",
        "  return t\n",
        "  # return (features.T @ features) / (features.shape[0])\n",
        "\n",
        "def get_sigma_B(mu_C_list,mu_G):\n",
        "  sigma_B = torch.zeros((mu_G.shape[0],mu_G.shape[0]),device=device)\n",
        "  for mu_C in mu_C_list:\n",
        "    diff = mu_C - mu_G\n",
        "    sigma_B += diff.unsqueeze(1) @ diff.unsqueeze(0) # Corrected outer product\n",
        "  sigma_B /= len(mu_C_list)\n",
        "  return sigma_B\n",
        "\n",
        "def get_mu_C_list(features,labels):\n",
        "  mu_C_list = []\n",
        "  for i in range(100):\n",
        "    mu_C_list.append(torch.mean(features[labels == i],dim=0).to(device))\n",
        "  return mu_C_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea1889e2",
      "metadata": {
        "id": "ea1889e2"
      },
      "source": [
        "## NC 1\n",
        "\n",
        "variability collapse : In class variations converges towards 0.\n",
        "$$\n",
        "\\Sigma_B \\to 0\n",
        "$$\n",
        "In practice we have\n",
        "$$\n",
        "Tr\\big [ \\frac {\\Sigma_W \\Sigma_B ^ † } C \\big ]\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f78d2f44",
      "metadata": {
        "id": "f78d2f44"
      },
      "outputs": [],
      "source": [
        "def nc1(sigma_W):\n",
        "  return torch.linalg.norm(sigma_W)\n",
        "\n",
        "def train_class_means_equinorm(mu_C_list,mu_G):\n",
        "  centered_norms = []\n",
        "  for key in range(len(mu_C_list)):\n",
        "    centered_norms.append(torch.linalg.norm(mu_C_list[key] - mu_G))\n",
        "  #Fig 2\n",
        "  centered_norms = torch.tensor(centered_norms,device=device)\n",
        "  return torch.std(centered_norms) / torch.mean(centered_norms)\n",
        "\n",
        "def train_class_weights_equinorm(weights):\n",
        "  norm = torch.linalg.norm(weights,dim=1)\n",
        "  # print(norm.shape)\n",
        "  # print(norm)\n",
        "  #Fig 2\n",
        "  m = torch.mean(norm)\n",
        "  s = torch.std(norm)\n",
        "  # print(m)\n",
        "  # print(s)\n",
        "  return  s/m\n",
        "\n",
        "def scale_invariante_nc1(Sigma_W, Sigma_B,C=100):\n",
        "    \"\"\"\n",
        "    Computes the NC1 metric: 1/C * Trace(Sigma_W * pinv(Sigma_B))\n",
        "    \"\"\"\n",
        "    C = 100 # Number of classes\n",
        "    Sigma_B_pinv = torch.linalg.pinv(Sigma_B, rcond=1e-6)\n",
        "    # NC1 = 1/C * Trace(Sigma_W @ Sigma_B_pinv)\n",
        "    nc1_value = torch.trace(Sigma_W @ Sigma_B_pinv) / float(C)\n",
        "\n",
        "    #Fig 6\n",
        "    return nc1_value.item()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e4bab00",
      "metadata": {
        "id": "6e4bab00"
      },
      "source": [
        "## NC 2\n",
        "\n",
        "As training progresses, the standard deviations of the cosines approach zero\n",
        "indicating equiangularity\n",
        "\n",
        "$$\n",
        "\\left| \\|\\mu_c - \\mu_G\\|_2 - \\|\\mu_{c'} - \\mu_G\\|_2 \\right| \\to 0 \\quad \\forall c, c'\n",
        "$$\n",
        "$$\n",
        "    \\langle \\tilde{\\mu}_c, \\tilde{\\mu}_{c'} \\rangle \\to \\frac{C}{C-1} \\delta_{c,c'} - \\frac{1}{C-1} \\quad \\forall c, c'\n",
        "$$\n",
        "In practice we have\n",
        "$$\n",
        "EN_{\\text{class-means}} = \\frac{std_c\\{ \\|\\mu_c - \\mu_G\\|_2 \\}}{avg_c\\{ \\|\\mu_c - \\mu_G\\|_2 \\}}\n",
        "$$\n",
        "\n",
        "and\n",
        "$$\n",
        "\\text{Equiangularity}_{\\text{class-means}} = Avg_{c,c'} \\big | \\frac{ \\langle {\\mu}_c-{\\mu}_G, {\\mu}_{c'} - {\\mu}_G \\rangle  + \\frac 1 {C-1} } {\\|\\mu_c - \\mu_G\\|_2\\|\\mu_c' - \\mu_G\\|_2}   \\big |\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yy3QCk61zYxP",
      "metadata": {
        "id": "yy3QCk61zYxP"
      },
      "outputs": [],
      "source": [
        "def nc2(mu_C_list,mu_G):\n",
        "  C = len(mu_C_list)\n",
        "  class_cos_sim = []\n",
        "  for key in range(C):\n",
        "    for key2 in range(key+1,C):\n",
        "      norm=  (mu_C_list[key] -mu_G )@ (mu_C_list[key2] - mu_G)\n",
        "      norm = norm/(torch.linalg.norm(mu_C_list[key] - mu_G)*torch.linalg.norm(mu_C_list[key2] - mu_G))\n",
        "      class_cos_sim.append(norm)\n",
        "\n",
        "  class_cos_sim = torch.tensor(class_cos_sim,device=device)\n",
        "  vals_2 = torch.std(class_cos_sim)\n",
        "  vals_3 = class_cos_sim + 1.0/(C - 1)\n",
        "  vals_3 = torch.mean(vals_3)\n",
        "  #Fig 3, Fig 4\n",
        "  return vals_2,vals_3\n",
        "\n",
        "def nc2_weights(weights):\n",
        "  C = weights.shape[0]\n",
        "  cosses = weights @ weights.T\n",
        "  norms = torch.norm(weights, dim=1, keepdim=True)\n",
        "  cosses = (weights @ weights.T) / (norms @ norms.T)\n",
        "  cosses = cosses / norms\n",
        "  #Fig 3, Fig 4\n",
        "  #remove cos(x,x)\n",
        "  mask = ~torch.eye(C, dtype=bool, device=weights.device)\n",
        "  cosses = cosses[mask]\n",
        "  vals_2 = torch.std(cosses)\n",
        "\n",
        "  vals_3 = cosses + 1.0/(C - 1)\n",
        "  vals_3 = torch.mean(vals_3)\n",
        "\n",
        "  return vals_2,vals_3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8f76640",
      "metadata": {
        "id": "d8f76640"
      },
      "source": [
        "## NC 3\n",
        "\n",
        " Convergence to self-duality:\n",
        "\n",
        "$$ \\left\\| \\frac{W^T}{\\|W|_F} - \\frac{\\dot M}{\\|\\dot M|_F}\\right\\|_F \\to 0$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NzRcgH5r5j5U",
      "metadata": {
        "id": "NzRcgH5r5j5U"
      },
      "outputs": [],
      "source": [
        "def nc3(mu_C_list,mu_G,W):\n",
        "  mu_C_list = torch.stack(mu_C_list) - mu_G\n",
        "  mu_C_list = mu_C_list / torch.linalg.norm(mu_C_list,dim=1,keepdim=True)\n",
        "\n",
        "  W = W / torch.linalg.norm(W,dim=1,keepdim=True)\n",
        "\n",
        "  #Fig 5\n",
        "  return torch.linalg.norm(mu_C_list - W)**2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84f0b7be",
      "metadata": {
        "id": "84f0b7be"
      },
      "source": [
        "## NC 4\n",
        "Simplification to NCC\n",
        "$$ arg\\max_{c'} \\left< w_{c'}, h \\right> + b_{c'} \\to \\arg\\min_{c'} \\|h - \\mu_{c'}\\|_2 $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jcaA6RZs9Vo1",
      "metadata": {
        "id": "jcaA6RZs9Vo1"
      },
      "outputs": [],
      "source": [
        "def compute_nc4_disagreement(features, mpred, mu_C_list):\n",
        "    \"\"\"\n",
        "    Computes the disagreement between the model's logits and the NCC rule.\n",
        "\n",
        "    Args:\n",
        "        features (N, d): Penultimate layer features.\n",
        "        logits (N, C): Model output (before softmax).\n",
        "        class_means (C, d): The computed mu_c for each class.\n",
        "\n",
        "    Returns:\n",
        "        disagreement_rate (float): Percentage of samples where Model != NCC.\n",
        "    \"\"\"\n",
        "    # Compute NCC predictions using vectorized L2 distance:\n",
        "    # ||h - mu||^2 = ||h||^2 + ||mu||^2 - 2<h, mu>\n",
        "    h_squared = torch.sum(features**2, dim=1, keepdim=True)      # (N, 1)\n",
        "    class_means = torch.stack(mu_C_list)\n",
        "    mu_squared = torch.sum(class_means**2, dim=1, keepdim=True).T # (1, C)\n",
        "    distances = h_squared + mu_squared - 2 * (features @ class_means.T)\n",
        "\n",
        "    ncc_preds = torch.argmin(distances, dim=1)\n",
        "    disagreement = (mpred != ncc_preds).float().mean()\n",
        "    # Fig 7\n",
        "    return disagreement.item()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eec19a17",
      "metadata": {
        "id": "eec19a17"
      },
      "source": [
        "## NC 5\n",
        "\n",
        "As training progresses, the clusters of OOD become increasingly orthgonal to the ETF subspace of the ID data.\n",
        "\n",
        "$$\n",
        "\\text{OrthoDev}_\\text{classes−OOD} = \\text{Avg}_c \\big | \\frac{ \\langle {\\mu}_c, {\\mu}_{G}^{OOD} \\rangle } {\\|\\mu_c  \\|_2\\| {\\mu}_{G}^{OOD} \\|_2}     \\big |\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zZXk2DNACHMO",
      "metadata": {
        "id": "zZXk2DNACHMO"
      },
      "outputs": [],
      "source": [
        "def nc5(mu_C_list,mu_G_OOD):\n",
        "  tmp = 0.0\n",
        "  for mu_C in mu_C_list:\n",
        "    tmp += F.cosine_similarity(mu_C,mu_G_OOD,dim=0)\n",
        "  return tmp / len(mu_C_list)\n",
        "\n",
        "\n",
        "def generate_ood_mu_G(mu_G):\n",
        "  # Generate a random vector in the same space as mu_G\n",
        "  random_vector = torch.randn_like(mu_G)\n",
        "  # Normalize it to have the same norm as mu_G\n",
        "  random_vector = random_vector / torch.linalg.norm(random_vector) * torch.linalg.norm(mu_G)\n",
        "  return random_vector.to(device)\n",
        "\n",
        "#or use SVHN dataset as OOD\n",
        "\n",
        "def load_svhn_OOD(batch_size):\n",
        "    tr_svhn = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "    ])\n",
        "    svhn_data = torchvision.datasets.SVHN(\n",
        "        root=\"./data\", split='test', download=True, transform=tr_svhn\n",
        "    )\n",
        "    svhn_dataloader = torch.utils.data.DataLoader(svhn_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    #only select 1000 samples to compute mu_G_OOD\n",
        "    svhn_subset = torch.utils.data.Subset(svhn_data, range(10000))\n",
        "    svhn_subset_dataloader = torch.utils.data.DataLoader(svhn_subset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    return svhn_dataloader, svhn_subset_dataloader\n",
        "\n",
        "def compute_ood_mu_G(resnet, svhn_subset_dataloader):\n",
        "    resnet.eval()\n",
        "    features = torch.tensor([], requires_grad=False, device=device)\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in tqdm(svhn_subset_dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            out = resnet.model(inputs)\n",
        "            features = torch.cat((features, out))\n",
        "    mu_G_OOD = torch.mean(features, dim=0).to(device)\n",
        "    return mu_G_OOD\n",
        "\n",
        "\n",
        "\n",
        "def compute_ood_noise_mu_G(resnet,batch_size=64,nb_samples= 1000):\n",
        "    resnet.eval()\n",
        "    features = torch.tensor([], requires_grad=False, device=device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0,nb_samples,batch_size):\n",
        "            inputs = torch.randn(batch_size,3,32,32).to(device)\n",
        "\n",
        "            out = resnet.model(inputs)\n",
        "            features = torch.cat((features, out),dim=0)\n",
        "    mu_G_OOD = torch.mean(features, dim=0).to(device)\n",
        "    return mu_G_OOD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ivtyV92U35Jx",
      "metadata": {
        "id": "ivtyV92U35Jx"
      },
      "source": [
        "# NECO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i__A3MWn34jP",
      "metadata": {
        "id": "i__A3MWn34jP"
      },
      "outputs": [],
      "source": [
        "def neco(P,h_pred,threshold=0.1 ):\n",
        "  tmp= torch.linalg.norm(P@ h_pred)/torch.linalg.norm(h_pred)\n",
        "  return tmp, tmp < threshold\n",
        "\n",
        "\n",
        "def generate_P(H,d):\n",
        "  _,_,V = torch.pca_lowrank(H,q=d)\n",
        "  return V.T\n",
        "\n",
        "def neco_maxlogit(P,h_pred,threshold=0.1):\n",
        "  maxlogit = torch.max(h_pred,dim=0).values\n",
        "  h_pred = h_pred * maxlogit\n",
        "  tmp= torch.linalg.norm(P@h_pred)/torch.linalg.norm(h_pred)\n",
        "  return tmp, tmp < threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XiltBe3vCIDh",
      "metadata": {
        "id": "XiltBe3vCIDh"
      },
      "source": [
        "# Computing NC values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e338fe5",
      "metadata": {
        "id": "8e338fe5"
      },
      "outputs": [],
      "source": [
        "fig2_1,fig2_2, fig3 , fig4 ,fig5, fig6, fig7 =[],[],[],[],[],[],[]\n",
        "fig3_2 , fig4_2 = [],[]\n",
        "nc1_fig = []\n",
        "nc5_fig = []\n",
        "nc5_noised_fig = []\n",
        "_, svhn_subset_dataloader = load_svhn_OOD(batch_size)\n",
        "for i in range(10,361,10):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  path = f\"/content/drive/MyDrive/Cours/ensta cours/model/resnet_{i}_epoch.pth\"\n",
        "  resnet = load_model(path)\n",
        "  features,labels,W,pred = compute_features(resnet,train_dataloader)\n",
        "\n",
        "  mu_G = get_mu_G(features)\n",
        "  sigma_T = get_sigma_T(features,mu_G)\n",
        "  mu_C_list = get_mu_C_list(features,labels)\n",
        "  sigma_B = get_sigma_B(mu_C_list,mu_G)\n",
        "  mu_G_OOD = compute_ood_mu_G(resnet, svhn_subset_dataloader)\n",
        "  mu_G_OOD_noised = compute_ood_noise_mu_G(resnet)\n",
        "  del resnet\n",
        "\n",
        "  # print(\"features :\",features.shape)\n",
        "  # print(\"labels :\",labels.shape)\n",
        "  # print(\"W :\",W.shape)\n",
        "  # print(\"pred :\",pred.shape)\n",
        "  # print(\"mu_G :\",mu_G.shape)\n",
        "  # print(\"mu_C_list :\",len(mu_C_list))\n",
        "  # print(\"mu_C_list[0] :\",mu_C_list[0].shape)\n",
        "  # print(\"sigma_T :\",sigma_T.shape)\n",
        "  # print(\"sigma_B :\",sigma_B.shape)\n",
        "  # print(\"mu_G_OOD :\",mu_G_OOD.shape)\n",
        "\n",
        "  nc1_fig.append(nc1(sigma_T-sigma_B).item())\n",
        "  fig6.append(scale_invariante_nc1(sigma_T-sigma_B,sigma_B))\n",
        "  fig2_1.append(train_class_means_equinorm(mu_C_list,mu_G).item())\n",
        "  fig2_2.append(train_class_weights_equinorm(W).item())\n",
        "  x,y = nc2(mu_C_list,mu_G)\n",
        "  fig3.append(x.item())\n",
        "  fig4.append(y.item())\n",
        "  x,y = nc2_weights(W)\n",
        "  fig3_2.append(x.item())\n",
        "  fig4_2.append(y.item())\n",
        "  fig5.append(nc3(mu_C_list,mu_G,W).item())\n",
        "  fig7.append(compute_nc4_disagreement(features,pred, mu_C_list))\n",
        "  nc5_fig.append(nc5(mu_C_list,mu_G_OOD).item())\n",
        "  nc5_noised_fig.append(nc5(mu_C_list,mu_G_OOD_noised).item())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0555a366",
      "metadata": {
        "id": "0555a366"
      },
      "source": [
        "# Visualization of NC values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O_Qqm2dR1cV5",
      "metadata": {
        "id": "O_Qqm2dR1cV5"
      },
      "outputs": [],
      "source": [
        "timeline = [i for i in range(10,361,10)]\n",
        "df = pd.DataFrame(\n",
        "    {\n",
        "        \"epochs\":timeline,\n",
        "        \"nc1_fig\":nc1_fig,\n",
        "        \"fig2_1_train_class_means_equinorm\":fig2_1,\n",
        "        \"fig2_2_train_class_weights_equinorm\":fig2_2,\n",
        "        \"fig3_nc2_std_cos_sim\":fig3,\n",
        "        \"fig3_2_nc2_weights_std_cos_sim\":fig3_2,\n",
        "        \"fig4_nc2_mean_cos_sim\":fig4,\n",
        "        \"fig4_2_nc2_weights_mean_cos_sim\":fig4_2,\n",
        "        \"fig5_nc3\":fig5,\n",
        "        \"fig6_nc1_scale_invariant\":fig6,\n",
        "        \"fig7_nc4_disagreement\":fig7,\n",
        "        \"fig8_nc5\":nc5_fig,\n",
        "        \"fig8_nc5_noised\":nc5_noised_fig\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UIzomH1b2Y-i",
      "metadata": {
        "id": "UIzomH1b2Y-i"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"nc_values.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kLN6D6Ktj5Vi",
      "metadata": {
        "id": "kLN6D6Ktj5Vi"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UO1HVlPwbEN9",
      "metadata": {
        "id": "UO1HVlPwbEN9"
      },
      "outputs": [],
      "source": [
        "#plot df\n",
        "def plot_nc_dataframe(df):\n",
        "    \"\"\"\n",
        "    Plots all columns in df against 'epochs'.\n",
        "    Assumes df contains an 'epochs' column.\n",
        "    \"\"\"\n",
        "\n",
        "    if \"epochs\" not in df.columns:\n",
        "        raise ValueError(\"DataFrame must contain an 'epochs' column.\")\n",
        "\n",
        "    metrics = [col for col in df.columns if col != \"epochs\"]\n",
        "\n",
        "    for metric in metrics:\n",
        "        plt.figure()\n",
        "        plt.plot(df[\"epochs\"], df[metric])\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(metric)\n",
        "        plt.title(f\"{metric} vs Epochs\")\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GW7lN6jzbZyG",
      "metadata": {
        "id": "GW7lN6jzbZyG"
      },
      "outputs": [],
      "source": [
        "plot_nc_dataframe(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RIaeXph0lF2O",
      "metadata": {
        "id": "RIaeXph0lF2O"
      },
      "outputs": [],
      "source": [
        "plt.plot(nc5_noised_fig)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P7cf9UT7jHTW",
      "metadata": {
        "id": "P7cf9UT7jHTW"
      },
      "outputs": [],
      "source": [
        "def plot_nc_per_figure(df):\n",
        "    if \"epochs\" not in df.columns:\n",
        "        raise ValueError(\"DataFrame must contain an 'epochs' column.\")\n",
        "\n",
        "    epochs = df[\"epochs\"]\n",
        "\n",
        "    figures = {\n",
        "        \"Fig1_NC1\": [\"nc1_fig\"],\n",
        "        \"Fig2_Equinorm\": [\n",
        "            \"fig2_1_train_class_means_equinorm\",\n",
        "            \"fig2_2_train_class_weights_equinorm\"\n",
        "        ],\n",
        "        \"Fig3_NC2_STD\": [\n",
        "            \"fig3_nc2_std_cos_sim\",\n",
        "            \"fig3_2_nc2_weights_std_cos_sim\"\n",
        "        ],\n",
        "        \"Fig4_NC2_MEAN\": [\n",
        "            \"fig4_nc2_mean_cos_sim\",\n",
        "            \"fig4_2_nc2_weights_mean_cos_sim\"\n",
        "        ],\n",
        "        \"Fig5_NC3\": [\"fig5_nc3\"],\n",
        "        \"Fig6_NC1_ScaleInvariant\": [\"fig6_nc1_scale_invariant\"],\n",
        "        \"Fig7_NC4\": [\"fig7_nc4_disagreement\"],\n",
        "        \"Fig8_NC5\": [\"fig8_nc5\"],\n",
        "    }\n",
        "\n",
        "    for title, cols in figures.items():\n",
        "        existing = [c for c in cols if c in df.columns]\n",
        "        if not existing:\n",
        "            continue\n",
        "\n",
        "        plt.figure()\n",
        "        for col in existing:\n",
        "            plt.plot(epochs, df[col], label=col)\n",
        "\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.title(title)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        #save plt\n",
        "        plt.savefig(f\"{title}.png\")\n",
        "        plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "krHTjHO4jXOU",
      "metadata": {
        "id": "krHTjHO4jXOU"
      },
      "outputs": [],
      "source": [
        "plot_nc_per_figure(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a7f34aa",
      "metadata": {
        "id": "0a7f34aa"
      },
      "source": [
        "# NECO testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cgiupmWXlPTx",
      "metadata": {
        "id": "cgiupmWXlPTx"
      },
      "outputs": [],
      "source": [
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SyAwbn5dlQY1",
      "metadata": {
        "id": "SyAwbn5dlQY1"
      },
      "outputs": [],
      "source": [
        "P = generate_P(features,360)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = load_model(\"/content/drive/MyDrive/Cours/ensta cours/model/resnet_360_epoch.pth\")"
      ],
      "metadata": {
        "id": "h8dGhW19EeUc"
      },
      "id": "h8dGhW19EeUc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t =torch.randn(1,3,32,32).to(device)\n",
        "output = resnet.model(t)\n",
        "output = output.T\n",
        "n,_ = neco(P,output)\n",
        "print(\"neco value :\",n)\n",
        "n,_ = neco_maxlogit(P,output)\n",
        "print(\"neco max logit value :\",n)"
      ],
      "metadata": {
        "id": "0o_hcvoKE1Hu"
      },
      "id": "0o_hcvoKE1Hu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CanVh0r_FJ4I"
      },
      "id": "CanVh0r_FJ4I",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}